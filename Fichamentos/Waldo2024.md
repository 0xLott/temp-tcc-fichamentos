# GPTs and Hallucination: Why do large language models hallucinate?

Jim Waldo and Soline Boussard. 2024. GPTs and Hallucination: Why do large language models hallucinate? Queue 22, 4, Pages 10 (July/August 2024), 15 pages. https://doi.org/10.1145/3688007

## 1. Fichamento de Conteúdo

O artigo explora o funcionamento dos modelos de linguagem de grande escala (LLMs), como os GPTs, e discute os desafios relacionados à confiança do conhecimento oferecido e ao fenômeno de "alucinação" (geração de informações incorretas ou irreais). Os autores explicam que os LLMs operam com base em probabilidades estatísticas de co-ocorrência de palavras, sem compreensão semântica ou conexão com fatos do mundo real. Isso leva à questão central: por que os GPTs acertam em algumas situações e erram (ou "alucinam") em outras? O artigo traça um paralelo histórico entre os mecanismos de confiança epistêmica, desde a autoridade de figuras antigas até a ciência moderna baseada em experimentação e revisão por pares, e como a confiança em fontes de conhecimento evoluiu para incluir práticas de crowdsourcing, como Wikipedia e Reddit. Os autores propõem que os LLMs representam a próxima etapa nessa evolução, gerando respostas com base no consenso implícito nos dados de treinamento. Eles testam a hipótese de que a alucinação é mais provável em tópicos obscuros ou controversos, onde há menos consenso ou dados disponíveis. Os resultados mostram variações na precisão das respostas de diferentes LLMs (como ChatGPT-4, Google Gemini e Llama), destacando que a confiabilidade das respostas depende da clareza dos dados sobre o tópico em questão.

## 2. Fichamento Bibliográfico

- _"Hallucination"_: Fenômeno em que modelos de linguagem geram informações incorretas ou irreais, frequentemente devido à falta de dados consistentes ou consenso sobre o tópico.
- _Confiança Epistêmica_: A confiança depositada em uma afirmação ou fonte de conhecimento, baseada em mecanismos como experimentação científica, revisão por pares ou consenso de crowdsourcing.
- _Crowdsourcing_: Prática de obter conhecimento ou soluções por meio da colaboração de um grande grupo de pessoas, como em plataformas online (ex.: Wikipedia, Reddit, StackOverflow).

## 3. Fichamento de Citações

- "_In a viral instance, the New York Times published an article about a lawyer who used ChatGPT to produce case citations without realizing they were fictional, or hallucinated_"
- "_[...] which word comes next has nothing to do with its semantic meaning or what is true in the real world; instead, it has to do with what has been found to be most likely in looking at all of the words and where they occur in the training set_"
- "_LLMs and the generative pretrained transformers built on those models do fit the pattern of crowdsourcing, drawing as they do on the discourse embodied in their training sets._"
